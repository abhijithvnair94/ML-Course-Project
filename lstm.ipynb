{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "project.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/reeshabhkumarranjan/ML-Course-Project/blob/master/lstm.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W-rTNdvqI6dy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# imports\n",
        "import numpy as np\n",
        "import glob\n",
        "from keras import Sequential\n",
        "import sklearn, sklearn.model_selection\n",
        "from keras import Sequential\n",
        "from keras.layers import LSTM, Dropout, Dense, TimeDistributed, Conv1D, MaxPooling1D, Flatten, ConvLSTM2D, Activation\n",
        "from keras.utils import to_categorical"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GqJr6jhBQ_XJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4a655219-eec8-4b1d-988e-3bb5e0766086"
      },
      "source": [
        "# mounting drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# loading data\n",
        "colab_directory = '/content/drive/My Drive/Colab Notebooks/ML Course Project/'\n",
        "x = np.load(colab_directory + \"x.npy\")\n",
        "y = np.load(colab_directory + \"y.npy\")\n",
        "x_train, x_test, y_train, y_test = sklearn.model_selection.train_test_split(x, y, test_size=0.2, random_state=2)\n",
        "y_train = to_categorical(y_train)\n",
        "y_test = to_categorical(y_test)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZMXJYiV5PBnQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# common variables\n",
        "epochs = 30\n",
        "showWorking = True\n",
        "batchSize = 200\n",
        "dropoutRate = 0.3"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DsZrSlbhANs1",
        "colab_type": "code",
        "outputId": "37d3bce7-84a0-43c3-aea5-173988092fec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# LSTM model\n",
        "model_lstm = Sequential([\n",
        "\tLSTM(200, input_shape=(x_train.shape[1], x_train.shape[2])),\n",
        "\tDropout(dropoutRate),\n",
        "\tDense(200),\n",
        "\tActivation('relu'),\n",
        "\tDense(y_train.shape[1]),\n",
        "\tActivation('softmax'),\n",
        "])\n",
        "model_lstm.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model_lstm.fit(x_train, y_train, epochs=epochs, batch_size=batchSize, verbose=showWorking)\n",
        "useless, accuracy = model_lstm.evaluate(x_test, y_test, batch_size=batchSize, verbose=showWorking)\n",
        "print(\"Accuracy of LSTM model on test: \", accuracy)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "396/396 [==============================] - 5s 12ms/step - loss: 1.0896 - acc: 0.3510\n",
            "Epoch 2/30\n",
            "396/396 [==============================] - 0s 775us/step - loss: 1.0481 - acc: 0.4268\n",
            "Epoch 3/30\n",
            "396/396 [==============================] - 0s 784us/step - loss: 1.0130 - acc: 0.4394\n",
            "Epoch 4/30\n",
            "396/396 [==============================] - 0s 801us/step - loss: 0.9548 - acc: 0.5732\n",
            "Epoch 5/30\n",
            "396/396 [==============================] - 0s 720us/step - loss: 0.8244 - acc: 0.7071\n",
            "Epoch 6/30\n",
            "396/396 [==============================] - 0s 690us/step - loss: 0.6177 - acc: 0.7677\n",
            "Epoch 7/30\n",
            "396/396 [==============================] - 0s 701us/step - loss: 0.8618 - acc: 0.5859\n",
            "Epoch 8/30\n",
            "396/396 [==============================] - 0s 690us/step - loss: 1.1926 - acc: 0.3131\n",
            "Epoch 9/30\n",
            "396/396 [==============================] - 0s 729us/step - loss: 1.0696 - acc: 0.4343\n",
            "Epoch 10/30\n",
            "396/396 [==============================] - 0s 789us/step - loss: 0.8696 - acc: 0.5884\n",
            "Epoch 11/30\n",
            "396/396 [==============================] - 0s 740us/step - loss: 0.7504 - acc: 0.6616\n",
            "Epoch 12/30\n",
            "396/396 [==============================] - 0s 721us/step - loss: 0.7063 - acc: 0.7045\n",
            "Epoch 13/30\n",
            "396/396 [==============================] - 0s 773us/step - loss: 0.7476 - acc: 0.4924\n",
            "Epoch 14/30\n",
            "396/396 [==============================] - 0s 716us/step - loss: 0.7755 - acc: 0.3712\n",
            "Epoch 15/30\n",
            "396/396 [==============================] - 0s 676us/step - loss: 0.6950 - acc: 0.5808\n",
            "Epoch 16/30\n",
            "396/396 [==============================] - 0s 699us/step - loss: 0.6354 - acc: 0.7146\n",
            "Epoch 17/30\n",
            "396/396 [==============================] - 0s 691us/step - loss: 0.6295 - acc: 0.7323\n",
            "Epoch 18/30\n",
            "396/396 [==============================] - 0s 691us/step - loss: 0.6173 - acc: 0.7449\n",
            "Epoch 19/30\n",
            "396/396 [==============================] - 0s 661us/step - loss: 0.5879 - acc: 0.7904\n",
            "Epoch 20/30\n",
            "396/396 [==============================] - 0s 680us/step - loss: 0.5597 - acc: 0.8409\n",
            "Epoch 21/30\n",
            "396/396 [==============================] - 0s 660us/step - loss: 0.5246 - acc: 0.8636\n",
            "Epoch 22/30\n",
            "396/396 [==============================] - 0s 738us/step - loss: 0.5031 - acc: 0.8485\n",
            "Epoch 23/30\n",
            "396/396 [==============================] - 0s 831us/step - loss: 0.4539 - acc: 0.8864\n",
            "Epoch 24/30\n",
            "396/396 [==============================] - 0s 789us/step - loss: 0.4048 - acc: 0.9192\n",
            "Epoch 25/30\n",
            "396/396 [==============================] - 0s 728us/step - loss: 0.3626 - acc: 0.9217\n",
            "Epoch 26/30\n",
            "396/396 [==============================] - 0s 664us/step - loss: 0.3201 - acc: 0.9217\n",
            "Epoch 27/30\n",
            "396/396 [==============================] - 0s 768us/step - loss: 0.2808 - acc: 0.9343\n",
            "Epoch 28/30\n",
            "396/396 [==============================] - 0s 743us/step - loss: 0.2608 - acc: 0.9293\n",
            "Epoch 29/30\n",
            "396/396 [==============================] - 0s 697us/step - loss: 0.2382 - acc: 0.9343\n",
            "Epoch 30/30\n",
            "396/396 [==============================] - 0s 684us/step - loss: 0.2193 - acc: 0.9343\n",
            "100/100 [==============================] - 2s 18ms/step\n",
            "Accuracy of LSTM model on test:  0.9200000166893005\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U7aai0_qEzHo",
        "colab_type": "code",
        "outputId": "8d861a0b-4073-48fb-fefb-5f09deb67650",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# CNN-LSTM\n",
        "trainX = x_train.reshape((x_train.shape[0], 3, 20, x_train.shape[2]))\n",
        "testX = x_test.reshape((x_test.shape[0], 3, 20, x_test.shape[2]))\n",
        "\n",
        "conv1 = Conv1D(filters=64, kernel_size=5, activation='relu')\n",
        "conv2 = Conv1D(filters=64, kernel_size=5, activation='relu')\n",
        "model_lstm_cnn = Sequential([\n",
        "\tTimeDistributed(conv1, input_shape=(None, 20, x_train.shape[2])),\n",
        "\tTimeDistributed(conv2),\n",
        "\tTimeDistributed(Dropout(dropoutRate)),\n",
        "\tTimeDistributed(MaxPooling1D(pool_size=2)),\n",
        "\tTimeDistributed(Flatten()),\n",
        "\tLSTM(200),\n",
        "\tDropout(dropoutRate),\n",
        "\tDense(200),\n",
        "\tActivation('relu'),\n",
        "\tDense(y_train.shape[1]),\n",
        "\tActivation('softmax')\n",
        "])\n",
        "model_lstm_cnn.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model_lstm_cnn.fit(trainX, y_train, epochs=epochs, batch_size=batchSize, verbose=showWorking)\n",
        "useless, accuracy = model_lstm_cnn.evaluate(testX, y_test, batch_size=batchSize, verbose=showWorking)\n",
        "print(\"Accuracy on test-set for LSTM-CNN: \", accuracy)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "396/396 [==============================] - 5s 13ms/step - loss: 1.0860 - acc: 0.3763\n",
            "Epoch 2/30\n",
            "396/396 [==============================] - 0s 120us/step - loss: 1.0502 - acc: 0.4268\n",
            "Epoch 3/30\n",
            "396/396 [==============================] - 0s 127us/step - loss: 1.0147 - acc: 0.4293\n",
            "Epoch 4/30\n",
            "396/396 [==============================] - 0s 122us/step - loss: 0.9455 - acc: 0.6313\n",
            "Epoch 5/30\n",
            "396/396 [==============================] - 0s 124us/step - loss: 0.8439 - acc: 0.7146\n",
            "Epoch 6/30\n",
            "396/396 [==============================] - 0s 131us/step - loss: 0.6794 - acc: 0.7551\n",
            "Epoch 7/30\n",
            "396/396 [==============================] - 0s 133us/step - loss: 0.4993 - acc: 0.8384\n",
            "Epoch 8/30\n",
            "396/396 [==============================] - 0s 147us/step - loss: 0.3599 - acc: 0.8914\n",
            "Epoch 9/30\n",
            "396/396 [==============================] - 0s 140us/step - loss: 0.2677 - acc: 0.9242\n",
            "Epoch 10/30\n",
            "396/396 [==============================] - 0s 135us/step - loss: 0.3957 - acc: 0.8687\n",
            "Epoch 11/30\n",
            "396/396 [==============================] - 0s 128us/step - loss: 0.2650 - acc: 0.9293\n",
            "Epoch 12/30\n",
            "396/396 [==============================] - 0s 132us/step - loss: 0.2817 - acc: 0.9192\n",
            "Epoch 13/30\n",
            "396/396 [==============================] - 0s 123us/step - loss: 0.3137 - acc: 0.9040\n",
            "Epoch 14/30\n",
            "396/396 [==============================] - 0s 132us/step - loss: 0.2397 - acc: 0.9268\n",
            "Epoch 15/30\n",
            "396/396 [==============================] - 0s 130us/step - loss: 0.2510 - acc: 0.9242\n",
            "Epoch 16/30\n",
            "396/396 [==============================] - 0s 124us/step - loss: 0.2744 - acc: 0.9091\n",
            "Epoch 17/30\n",
            "396/396 [==============================] - 0s 122us/step - loss: 0.2057 - acc: 0.9394\n",
            "Epoch 18/30\n",
            "396/396 [==============================] - 0s 122us/step - loss: 0.2317 - acc: 0.9217\n",
            "Epoch 19/30\n",
            "396/396 [==============================] - 0s 132us/step - loss: 0.2025 - acc: 0.9343\n",
            "Epoch 20/30\n",
            "396/396 [==============================] - 0s 126us/step - loss: 0.2162 - acc: 0.9419\n",
            "Epoch 21/30\n",
            "396/396 [==============================] - 0s 122us/step - loss: 0.1935 - acc: 0.9470\n",
            "Epoch 22/30\n",
            "396/396 [==============================] - 0s 123us/step - loss: 0.1938 - acc: 0.9394\n",
            "Epoch 23/30\n",
            "396/396 [==============================] - 0s 122us/step - loss: 0.1716 - acc: 0.9470\n",
            "Epoch 24/30\n",
            "396/396 [==============================] - 0s 122us/step - loss: 0.1804 - acc: 0.9419\n",
            "Epoch 25/30\n",
            "396/396 [==============================] - 0s 134us/step - loss: 0.1675 - acc: 0.9470\n",
            "Epoch 26/30\n",
            "396/396 [==============================] - 0s 137us/step - loss: 0.1663 - acc: 0.9444\n",
            "Epoch 27/30\n",
            "396/396 [==============================] - 0s 151us/step - loss: 0.1556 - acc: 0.9495\n",
            "Epoch 28/30\n",
            "396/396 [==============================] - 0s 159us/step - loss: 0.1536 - acc: 0.9495\n",
            "Epoch 29/30\n",
            "396/396 [==============================] - 0s 133us/step - loss: 0.1610 - acc: 0.9470\n",
            "Epoch 30/30\n",
            "396/396 [==============================] - 0s 134us/step - loss: 0.1557 - acc: 0.9571\n",
            "100/100 [==============================] - 2s 19ms/step\n",
            "Accuracy on test-set for LSTM-CNN:  0.9300000071525574\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RXvEjbdJUvSP",
        "colab_type": "code",
        "outputId": "1112bfc7-230a-47f7-a77f-15bdb71c11a5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# LSTM + conv\n",
        "trainX = x_train.reshape((x_train.shape[0], 3, 1, 20, x_train.shape[2]))\n",
        "testX = x_test.reshape((x_test.shape[0], 3, 1, 20, x_test.shape[2]))\n",
        "\n",
        "model_lstm_conv = Sequential([\n",
        "\tConvLSTM2D(filters=100, kernel_size=(1,5), input_shape=(3, 1, 20, x_train.shape[2])),\n",
        "\tActivation('relu'),\n",
        "\tDropout(dropoutRate),\n",
        "\tFlatten(),\n",
        "\tDense(200),\n",
        "\tActivation('relu'),\n",
        "\tDense(y_train.shape[1]),\n",
        "\tActivation('softmax')\n",
        "])\n",
        "model_lstm_conv.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model_lstm_conv.fit(trainX, y_train, epochs=epochs, batch_size=batchSize, verbose=showWorking)\n",
        "useless, accuracy = model_lstm_conv.evaluate(testX, y_test, batch_size=batchSize, verbose=showWorking)\n",
        "print(\"Accuracy on test for LSTM-Conv: \", accuracy)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "396/396 [==============================] - 5s 14ms/step - loss: 1.0855 - acc: 0.3687\n",
            "Epoch 2/30\n",
            "396/396 [==============================] - 0s 281us/step - loss: 1.0362 - acc: 0.4268\n",
            "Epoch 3/30\n",
            "396/396 [==============================] - 0s 278us/step - loss: 0.9805 - acc: 0.4268\n",
            "Epoch 4/30\n",
            "396/396 [==============================] - 0s 242us/step - loss: 0.8855 - acc: 0.6919\n",
            "Epoch 5/30\n",
            "396/396 [==============================] - 0s 262us/step - loss: 0.7536 - acc: 0.8258\n",
            "Epoch 6/30\n",
            "396/396 [==============================] - 0s 244us/step - loss: 0.6101 - acc: 0.8157\n",
            "Epoch 7/30\n",
            "396/396 [==============================] - 0s 227us/step - loss: 0.4663 - acc: 0.8939\n",
            "Epoch 8/30\n",
            "396/396 [==============================] - 0s 224us/step - loss: 0.3652 - acc: 0.9066\n",
            "Epoch 9/30\n",
            "396/396 [==============================] - 0s 210us/step - loss: 0.3103 - acc: 0.9015\n",
            "Epoch 10/30\n",
            "396/396 [==============================] - 0s 200us/step - loss: 0.2861 - acc: 0.9192\n",
            "Epoch 11/30\n",
            "396/396 [==============================] - 0s 200us/step - loss: 0.2598 - acc: 0.9217\n",
            "Epoch 12/30\n",
            "396/396 [==============================] - 0s 200us/step - loss: 0.2540 - acc: 0.9268\n",
            "Epoch 13/30\n",
            "396/396 [==============================] - 0s 223us/step - loss: 0.2482 - acc: 0.9293\n",
            "Epoch 14/30\n",
            "396/396 [==============================] - 0s 212us/step - loss: 0.3202 - acc: 0.9015\n",
            "Epoch 15/30\n",
            "396/396 [==============================] - 0s 211us/step - loss: 0.2890 - acc: 0.9217\n",
            "Epoch 16/30\n",
            "396/396 [==============================] - 0s 224us/step - loss: 0.2565 - acc: 0.9167\n",
            "Epoch 17/30\n",
            "396/396 [==============================] - 0s 226us/step - loss: 0.2502 - acc: 0.9318\n",
            "Epoch 18/30\n",
            "396/396 [==============================] - 0s 216us/step - loss: 0.2321 - acc: 0.9419\n",
            "Epoch 19/30\n",
            "396/396 [==============================] - 0s 210us/step - loss: 0.2381 - acc: 0.9268\n",
            "Epoch 20/30\n",
            "396/396 [==============================] - 0s 211us/step - loss: 0.2369 - acc: 0.9293\n",
            "Epoch 21/30\n",
            "396/396 [==============================] - 0s 206us/step - loss: 0.2253 - acc: 0.9343\n",
            "Epoch 22/30\n",
            "396/396 [==============================] - 0s 209us/step - loss: 0.2118 - acc: 0.9369\n",
            "Epoch 23/30\n",
            "396/396 [==============================] - 0s 206us/step - loss: 0.2102 - acc: 0.9394\n",
            "Epoch 24/30\n",
            "396/396 [==============================] - 0s 218us/step - loss: 0.2138 - acc: 0.9369\n",
            "Epoch 25/30\n",
            "396/396 [==============================] - 0s 214us/step - loss: 0.2077 - acc: 0.9293\n",
            "Epoch 26/30\n",
            "396/396 [==============================] - 0s 216us/step - loss: 0.2067 - acc: 0.9343\n",
            "Epoch 27/30\n",
            "396/396 [==============================] - 0s 212us/step - loss: 0.1968 - acc: 0.9419\n",
            "Epoch 28/30\n",
            "396/396 [==============================] - 0s 215us/step - loss: 0.1957 - acc: 0.9394\n",
            "Epoch 29/30\n",
            "396/396 [==============================] - 0s 208us/step - loss: 0.1840 - acc: 0.9419\n",
            "Epoch 30/30\n",
            "396/396 [==============================] - 0s 206us/step - loss: 0.1857 - acc: 0.9419\n",
            "100/100 [==============================] - 2s 21ms/step\n",
            "Accuracy on test for LSTM-Conv:  0.9399999976158142\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}